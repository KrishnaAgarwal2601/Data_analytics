{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble Learning"
      ],
      "metadata": {
        "id": "JSddCDrh1xIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Ensemble Learning in machine learning? Explain the key idea\n",
        "behind it.\n",
        "- Ensemble learning is a technique where multiple models are combined to make predictions, with the core idea that diverse models, when aggregated, reduce errors better than any single model. By averaging or voting (bagging), training sequentially to correct prior mistakes (boosting), or learning how to combine different model outputs (stacking), ensembles improve generalization by reducing variance and/or bias, leading to higher accuracy, robustness to noise, and more reliable performance across datasets.\n",
        "\n",
        "2. What is the difference between Bagging and Boosting?\n",
        "- Bagging trains many base learners independently on different bootstrap samples and aggregates their predictions to reduce variance and combat overfitting; Random Forest is a classic example. Boosting trains base learners sequentially, each focusing on correcting the previous model’s errors, and combines them in a weighted manner to reduce bias, e.g., AdaBoost/Gradient Boosting. In short: bagging = parallel, variance reduction via averaging; boosting = sequential, bias reduction via reweighting.\n",
        "\n",
        "3. What is bootstrap sampling and what role does it play in Bagging methods\n",
        "like Random Forest?\n",
        "- Bootstrap sampling is the process of drawing training examples with replacement from the original dataset to create multiple “bootstrap” datasets of the same size. In bagging methods like Random Forest, each tree is trained on its own bootstrap sample, which makes the trees diverse. Aggregating their predictions reduces variance and overfitting, while out-of-bag (OOB) samples—those not selected for a given tree—enable an internal, unbiased estimate of generalization performance without a separate validation set.\n",
        "\n",
        "4. What are Out-of-Bag (OOB) samples and how is OOB score used to\n",
        "evaluate ensemble models?\n",
        "- Out-of-Bag (OOB) samples are the training instances not included in a given bootstrap sample when building a particular tree in a bagging ensemble (about 36.8% on average per tree). For each data point, predictions from only the trees where that point was OOB are aggregated to produce an OOB prediction; the OOB score is the resulting performance metric. This provides an internal, approximately unbiased estimate of generalization performance without a separate validation set and helps guide model selection and hyperparameter tuning.\n",
        "\n",
        "5. Compare feature importance analysis in a single Decision Tree vs. a\n",
        "Random Forest.\n",
        "- A single decision tree’s importance reflects each feature’s total impurity reduction across its own splits, which can be unstable and biased toward high-cardinality or noisy features, especially if the tree overfits on training data. In a Random Forest, importances are averaged over many trees trained on bootstrap samples and feature subsampling, yielding more stable, generalizable scores, though the same impurity-based bias can persist unless using alternative measures like permutation importance computed on held-out data. Practically, forests reduce variance in importance estimates compared with one tree, and pairing them with permutation importance helps counter biases and overfitting artifacts for more reliable attribution."
      ],
      "metadata": {
        "id": "g7ax-fwX14gq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B1irj7S21scE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20698169-4412-4dd6-8fb7-93522bc6694c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 features by importance:\n",
            "worst perimeter: 0.1373\n",
            "worst area: 0.1373\n",
            "worst concave points: 0.1155\n",
            "mean concave points: 0.0918\n",
            "worst radius: 0.0841\n"
          ]
        }
      ],
      "source": [
        "\"\"\" 6. Write a Python program to:\n",
        "● Load the Breast Cancer dataset using\n",
        "sklearn.datasets.load_breast_cancer()\n",
        "● Train a Random Forest Classifier\n",
        "● Print the top 5 most important features based on feature importance scores.\"\"\"\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "top_idx = np.argsort(importances)[::-1][:5]\n",
        "\n",
        "print(\"Top 5 features by importance:\")\n",
        "for i in top_idx:\n",
        "    print(f\"{feature_names[i]}: {importances[i]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 7. Write a Python program to:\n",
        "● Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "● Evaluate its accuracy and compare with a single Decision Tree \"\"\"\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_acc = accuracy_score(y_test, dt.predict(X_test))\n",
        "\n",
        "bag = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=100,\n",
        "    max_samples=1.0,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag.fit(X_train, y_train)\n",
        "bag_acc = accuracy_score(y_test, bag.predict(X_test))\n",
        "\n",
        "print(f\"Accuracy - Decision Tree: {dt_acc:.4f}\")\n",
        "print(f\"Accuracy - Bagging (100 trees): {bag_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFqSlJvp_dvv",
        "outputId": "6d90798b-b5be-447d-c068-2831f6fe8fab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy - Decision Tree: 0.9333\n",
            "Accuracy - Bagging (100 trees): 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 8. Write a Python program to:\n",
        "● Train a Random Forest Classifier\n",
        "● Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "● Print the best parameters and final accuracy \"\"\"\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100, 200, 300],\n",
        "    \"max_depth\": [None, 5, 10, 20]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    refit=True\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(f\"CV Best Score (mean accuracy): {grid.best_score_:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRBK1c2wAMk7",
        "outputId": "9b793ce9-7afe-4994-ee7f-592fe4f68d6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
            "CV Best Score (mean accuracy): 0.9604\n",
            "Test Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 9. Write a Python program to:\n",
        "● Train a Bagging Regressor and a Random Forest Regressor on the California\n",
        "Housing dataset\n",
        "● Compare their Mean Squared Errors (MSE) \"\"\"\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "bag = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(random_state=42),\n",
        "    n_estimators=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "bag.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "bag_mse = mean_squared_error(y_test, bag.predict(X_test))\n",
        "rf_mse = mean_squared_error(y_test, rf.predict(X_test))\n",
        "\n",
        "print(f\"MSE - BaggingRegressor: {bag_mse:.4f}\")\n",
        "print(f\"MSE - RandomForestRegressor: {rf_mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0XL0rY4Atcn",
        "outputId": "943cbb7c-d4eb-42e1-f04a-682b3afb5e20"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE - BaggingRegressor: 0.2559\n",
            "MSE - RandomForestRegressor: 0.2534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.  You are working as a data scientist at a financial institution to predict loan\n",
        "default. You have access to customer demographic and transaction history data.\n",
        "You decide to use ensemble techniques to increase model performance.\n",
        "Explain your step-by-step approach to:\n",
        "● Choose between Bagging or Boosting\n",
        "● Handle overfitting\n",
        "● Select base models\n",
        "● Evaluate performance using cross-validation\n",
        "● Justify how ensemble learning improves decision-making in this real-world\n",
        "context.\n",
        "\n",
        "- Choose method: start with bagging (Random Forest) if variance/overfitting is the main issue and features are mixed/tabular; choose boosting (XGBoost/LightGBM/CatBoost) when signal is weak and complex interactions matter, prioritizing recall for defaults; run quick baselines for both and select by cross-validated PR-AUC with business-weighted costs.\n",
        "- Handle overfitting: use out-of-fold tuning of depth, min_samples_leaf, subsampling (rows/cols), early stopping (for boosting), and monotonic constraints if needed; apply regularization (L1/L2 for boosted trees), and keep feature engineering within pipelines to avoid leakage.\n",
        "- Base models: for bagging use shallow-to-moderate depth decision trees; for boosting use gradient-boosted decision trees with appropriate categorical handling (e.g., CatBoost) and robust missing-value treatment; consider a simple logistic regression as a calibrated benchmark for stability.\n",
        "- Evaluation via CV: stratified K-fold with grouped/time-aware splits if temporal leakage risk exists; optimize PR-AUC/recall at fixed precision, report confusion matrix at the chosen threshold, and validate calibration (Brier score, calibration curve) plus segment-wise fairness (age, geography, product).\n",
        "- Business impact: improved risk discrimination reduces missed defaults (lower credit losses) while controlling false positives (customer experience and growth), enables risk-based pricing/limits, prioritizes collections, and supports explainable decisions (feature importances/SHAP) for compliance and auditability."
      ],
      "metadata": {
        "id": "DbQWsgEiBVUx"
      }
    }
  ]
}